{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TO-DO: Try PolynomialFeatures plus ridge regression/the lasso for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import iqr\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "charity = pd.read_csv('charity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def triola_id(data):\n",
    "    \n",
    "    '''\n",
    "    Function to check for unusual values in a feature column per Mario Triola's Elementary Statistics.\n",
    "    Data may be non-normally distributed. If a value is greater than ((1.5*IQR) + Q3), it is considered unusually high.\n",
    "    A value less than ((1.5*IQR) - Q1) is considered unsually low. Truncate features at max/min usual value.\n",
    "    Function follows code at https://machinelearningmastery.com/how-to-use-statistics-to-identify-outliers-in-data/.\n",
    "    \n",
    "    TO-DO: Try a version following \n",
    "    https://stackoverflow.com/questions/22354094/pythonic-way-of-detecting-outliers-in-one-dimensional-observation-data/22357811#22357811\n",
    "    '''\n",
    "    \n",
    "    q1_val, q3_val = data.quantile(.25), data.quantile(.75)\n",
    "    iqr_val = iqr(data)\n",
    "    iqr_cut = iqr_val * 1.5\n",
    "    min_us, max_us = q1_val - iqr_cut, q3_val + iqr_cut\n",
    "    return min_us, max_us\n",
    "\n",
    "test = charity.copy()\n",
    "test2 = charity.copy()\n",
    "test = test[['plow', 'incm', 'avhv']]\n",
    "test.apply(triola_trunc, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pause EDA until environmental issue with pandas_profiling can be worked out.\n",
    "# Work from known facts about the data from previous project version; dataset is the same file from 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dataset pre-prepared with designations for training/validation/testing split.\n",
    "# Normal response rate is around 10%, and training/validation sets have oversampled donors to address class imbalance.\n",
    "\n",
    "charity_train = charity.loc[charity['part'] == 'train']\n",
    "charity_train = charity_train.drop(columns = ['ID', 'part'])\n",
    "c_train = charity_train.pop('donr').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create pipeline manually specifying variables and transformations specified in paper.\n",
    "# Found a copy-paste error in original code with variables run as \"model 3\" over validation set in paper;\n",
    "# this set produced the lowest AIC on the *training* data in original project after correlation checks,\n",
    "# VIF checks, and fwd/bwd/stepwise selection.\n",
    "\n",
    "# Features specified with manual variable selection:\n",
    "#     -reg1 and reg2: Geographic regions in which potential donors live\n",
    "#     -hm_ch_int: Term indicating an interaction between home ownership and number of children\n",
    "#     -incm_tgif_int: Term indicating an interaction between median family income in the neighborhood\n",
    "#                     and total gifts given by the donor over his/her lifetime\n",
    "#     -hinc_sq: Square transform of household income categorization--in retrospect, this transform doesn't make\n",
    "#               sense to me. The square transform is used to reduce left skew \n",
    "#               (http://fmwww.bc.edu/repec/bocode/t/transint.html).\n",
    "#               This is really a categorical variable representing buckets of income values, not continuous.\n",
    "#               Removing for the purposes of this exercise. Might have been a given in project assignment.\n",
    "#     -wrat: Index of relative wealth within each state based on median family income and population stats. \n",
    "#            EDA section of paper indicates that more than half of all potential donors are in the top two \n",
    "#            categories, something that says to me now that it might be interesting to explore two buckets instead.\n",
    "#     -tdon: Time since last donation\n",
    "#     -tlag: Number of months between first and second gifts to the charity\n",
    "\n",
    "man_train = charity_train.copy()\n",
    "man_train['hm_ch_int'] = man_train['home'] * man_train['chld']\n",
    "man_train['incm_tgif_int'] = man_train['incm'] * man_train['tgif']\n",
    "man_train['hinc_sq'] = np.square(man_train['hinc'])\n",
    "man_train = man_train['reg1', 'reg2', 'hm_ch_int', 'incm_tgif_int', 'wrat', 'tdon', 'tlag']\n",
    "man_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TESTING: ColumnTransformer with logistic regression features identified in my course paper\n",
    "# Paper uses log transform to normalize data; sklearn has Box-Cox and Yeo-Johnson transforms.\n",
    "\n",
    "column_trans = ColumnTransformer(\n",
    "    [('incm_bc', pp.PowerTransformer(method='box-cox', standardize=False), ['incm']),\n",
    "    ('tgif_bc', pp.PowerTransformer(method='box-cox', standardize=False), ['tgif'])],\n",
    "    remainder='passthrough')\n",
    "\n",
    "man_trns = column_trans.fit_transform(man_train)\n",
    "man_trns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select predictive features, dropping ID value and target.\n",
    "# Python handles numbers differently, so cols are 1-21.\n",
    "\n",
    "x_train = charity_train.iloc[:, 1:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a label vector to hold donr values\n",
    "\n",
    "c_train = charity_train.iloc[:, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_train_len = len(c_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create response variable showing donation amounts for known donors.\n",
    "\n",
    "y_train = charity_train[(charity_train.donr == 1)][['damt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_len = len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "charity_valid = charity.loc[charity['part'] == 'valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_valid = charity_valid.iloc[:, 1:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_valid = charity_valid.iloc[:, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_valid = charity_valid[(charity_valid.donr == 1)][['damt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_valid_len = len(y_valid)\n",
    "y_valid_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "charity_test = charity.loc[charity['part'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = charity_test.iloc[:, 1:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardize features to zero mean and unit standard deviation for algorithms that require standardization.\n",
    "\n",
    "df_list = [x_train, x_test, x_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_std = scaler.fit_transform(x_train[x_train.columns]) # Need to send to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_valid_std = scaler.fit_transform(x_valid[x_valid.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_valid_std = scaler.fit_transform(x_test[x_test.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
